import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torchvision.models import resnet18
import numpy as np
import matplotlib
matplotlib.use('Agg') # åå°è¿è¡Œï¼Œé€‚åˆæœåŠ¡å™¨
import matplotlib.pyplot as plt
import cv2
import os

# ==========================================
# 1. åŸºç¡€é…ç½®
# ==========================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model_path = 'resnet18_stl10_lda.pth'  # ä½ çš„æ¨¡å‹æ–‡ä»¶å

# STL-10 çš„ç›®æ ‡ç±»åˆ«
target_classes = [0, 2, 8]  # é£æœº, æ±½è½¦, èˆ¹
class_names = ["Airplane", "Automobile", "Ship"]
label_map = {0: 0, 2: 1, 8: 2} # æ˜ å°„

transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
])


dataset = datasets.STL10(root='./data', split='test', download=True, transform=transform)

# ==========================================
# 2. Grad-CAM æ ¸å¿ƒç®—æ³•
# ==========================================
class GradCAM:
    def __init__(self, model, target_layer):
        self.model = model
        self.target_layer = target_layer
        self.gradients = None
        self.activations = None
        
        self.target_layer.register_forward_hook(self.save_activation)
        self.target_layer.register_full_backward_hook(self.save_gradient)

    def save_activation(self, module, input, output):
        self.activations = output

    def save_gradient(self, module, grad_input, grad_output):
        self.gradients = grad_output[0]

    def __call__(self, x, class_idx=None):
        output = self.model(x)
        if class_idx is None:
            class_idx = output.argmax(dim=1)
        
        self.model.zero_grad()
        score = output[:, class_idx].squeeze()
        score.backward()
        
        gradients = self.gradients.cpu().data.numpy()[0]
        activations = self.activations.cpu().data.numpy()[0]
        
        weights = np.mean(gradients, axis=(1, 2)) 
        cam = np.zeros(activations.shape[1:], dtype=np.float32)
        
        for i, w in enumerate(weights):
            cam += w * activations[i]
            
        cam = np.maximum(cam, 0)
        # Resize åˆ° 96x96 (STL-10 åŸç”Ÿå°ºå¯¸)
        cam = cv2.resize(cam, (96, 96)) 
        cam = cam - np.min(cam)
        cam = cam / (np.max(cam) + 1e-8)
        return cam, output

# ==========================================
# 3. âš ï¸ å…³é”®ï¼šå®Œç¾å¤åˆ»æ¨¡å‹ç»“æ„
# ==========================================
print(f"ğŸ“‚ åŠ è½½æ¨¡å‹: {model_path} ...")

# 1. åˆå§‹åŒ–æ ‡å‡† ResNet18
model = resnet18(weights=None) 

# 2. âš¡ï¸ ä¿®æ”¹ç»“æ„ä»¥åŒ¹é…è®­ç»ƒä»£ç  (è¿™å°±æ˜¯è§£å†³æŠ¥é”™çš„å…³é”®)
model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
model.maxpool = nn.Identity()
model.fc = nn.Linear(512, 3)

# 3. åŠ è½½å‚æ•°
try:
    model.load_state_dict(torch.load(model_path, map_location=device))
    print("âœ… æ¨¡å‹å‚æ•°åŠ è½½æˆåŠŸï¼")
except Exception as e:
    print(f"âŒ åŠ è½½å¤±è´¥: {e}")
    exit()

model.to(device)
model.eval()

# é”å®š Layer4 æœ€åä¸€å±‚
grad_cam = GradCAM(model, model.layer4[-1])

# ==========================================
# 4. æŒ‘é€‰å›¾ç‰‡å¹¶ç”Ÿæˆ Dashboard
# ==========================================
def denormalize(tensor):
    mean = np.array([0.485, 0.456, 0.406])
    std = np.array([0.229, 0.224, 0.225])
    img = tensor.permute(1, 2, 0).numpy()
    img = std * img + mean
    return np.clip(img, 0, 1)

# ç­›é€‰ç½®ä¿¡åº¦é«˜çš„å…¸å‹æ ·æœ¬
indices = []
print("ğŸ” ç­›é€‰æœ€ä½³æ ·æœ¬...")
# ç®€å•çš„ç­–ç•¥ï¼šæ¯ä¸ªç±»åˆ«éå†å‰50å¼ ï¼Œæ‰¾åˆ†ç±»æ­£ç¡®çš„
for target_cls in target_classes:
    found = False
    for i in range(len(dataset)):
        img, label = dataset[i]
        if label == target_cls:
            # ç®€å•éªŒè¯ä¸€ä¸‹æ¨¡å‹é¢„æµ‹æ˜¯å¦æ­£ç¡®ï¼Œç¡®ä¿ç”»å‡ºæ¥çš„å›¾æ˜¯æ¼‚äº®çš„
            with torch.no_grad():
                pred = model(img.unsqueeze(0).to(device)).argmax().item()
            if pred == label_map[target_cls]:
                indices.append(i)
                found = True
                break # æ¯ä¸ªç±»åªå–ä¸€å¼ 
    if not found:
        print(f"âš ï¸ Warning: æ²¡æ‰¾åˆ°ç±»åˆ« {target_cls} çš„åˆé€‚æ ·æœ¬")

# è®¾ç½®ç»˜å›¾é£æ ¼
plt.style.use('dark_background')
fig = plt.figure(figsize=(16, 9), dpi=200)
fig.suptitle(f"STL-10 XAI Dashboard: ResNet18 Reasoning Process", fontsize=24, fontweight='bold', color='white', y=0.98)

print("ğŸ¨ æ­£åœ¨æ¸²æŸ“å¯è§†åŒ–...")

for i, idx in enumerate(indices):
    img_tensor, label = dataset[idx]
    input_tensor = img_tensor.unsqueeze(0).to(device)
    mapped_label = label_map[label]
    
    # è·å–çƒ­åŠ›å›¾
    mask, output = grad_cam(input_tensor, mapped_label)
    
    # å‡†å¤‡å›¾ç‰‡
    raw_img = denormalize(img_tensor)
    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)
    heatmap = np.float32(heatmap) / 255
    heatmap = heatmap[..., ::-1]
    cam_img = 0.5 * heatmap + 0.5 * raw_img
    cam_img = np.clip(cam_img, 0, 1)

    # --- ç»˜å›¾ ---
    row = i * 5
    
    # 1. åŸå›¾
    ax1 = plt.subplot(3, 5, row + 1)
    ax1.imshow(raw_img)
    ax1.axis('off')
    ax1.text(-30, 48, class_names[mapped_label], fontsize=18, fontweight='bold', rotation=90, va='center', color='white')
    if i == 0: ax1.set_title("Input (96px)", fontsize=14, color='gray')

    # 2. çƒ­åŠ›å›¾
    ax2 = plt.subplot(3, 5, row + 2)
    ax2.imshow(mask, cmap='jet')
    ax2.axis('off')
    if i == 0: ax2.set_title("Attention", fontsize=14, color='gray')

    # 3. å åŠ 
    ax3 = plt.subplot(3, 5, row + 3)
    ax3.imshow(cam_img)
    ax3.axis('off')
    if i == 0: ax3.set_title("Reasoning", fontsize=14, color='gray')

    # 4. ç½®ä¿¡åº¦
    probs = F.softmax(output, dim=1).cpu().data.numpy()[0]
    ax4 = plt.subplot(3, 5, row + 4)
    colors = ['#FF4444', '#4444FF', '#44FF44'] # çº¢è“ç»¿
    bars = ax4.barh(class_names, probs, color=colors, alpha=0.8)
    ax4.set_xlim(0, 1.1)
    ax4.axis('off')
    # æ ‡æ•°å€¼
    for bar in bars:
        w = bar.get_width()
        ax4.text(w + 0.05, bar.get_y()+0.4, f"{w:.1%}", color='white', fontsize=10)
    # æ ‡ç±»åˆ«å
    for j, name in enumerate(class_names):
        ax4.text(-0.1, j, name, ha='right', va='center', color='white', fontsize=10)
    if i == 0: ax4.set_title("Confidence", fontsize=14, color='gray')

    # 5. ç‰¹å†™ (æ™ºèƒ½è£å‰ª)
    ax5 = plt.subplot(3, 5, row + 5)
    y_c, x_c = np.unravel_index(np.argmax(mask), mask.shape)
    margin = 24 # è£å‰ªèŒƒå›´
    y1, y2 = max(0, y_c-margin), min(96, y_c+margin)
    x1, x2 = max(0, x_c-margin), min(96, x_c+margin)
    crop = raw_img[y1:y2, x1:x2]
    
    # è°ƒæ•´ crop å¤§å°ä¸€è‡´æ˜¾ç¤º
    if crop.size > 0:
        ax5.imshow(crop)
        # ç”»ä¸ªæ¡†ç¤ºæ„æ”¾å¤§ä½ç½®
        rect = plt.Rectangle((x1, y1), x2-x1, y2-y1, linewidth=1.5, edgecolor='yellow', facecolor='none')
        ax3.add_patch(rect)
        
    ax5.axis('off')
    for spine in ax5.spines.values():
        spine.set_edgecolor('yellow')
        spine.set_linewidth(1.5)
        spine.set_visible(True)
    if i == 0: ax5.set_title("Focus Area", fontsize=14, color='gray')

plt.tight_layout(pad=1.5)
save_file = 'stl10_dashboard_fixed.png'
plt.savefig(save_file, dpi=200, bbox_inches='tight', facecolor='black')
print(f"âœ… å¯è§†åŒ–å›¾å·²ç”Ÿæˆ: {save_file}")