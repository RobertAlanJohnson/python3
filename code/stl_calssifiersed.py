import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import matplotlib
matplotlib.use('Agg')  # æœåŠ¡å™¨/åå°è¿è¡Œ
import matplotlib.pyplot as plt
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from matplotlib.colors import ListedColormap
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms
from torchvision.models import resnet18
import matplotlib.patches as mpatches

# ==========================================
# 1. é…ç½®ä¸æ•°æ®å‡†å¤‡ (é€‚é…STL-10 + å¢åŠ æ ·æœ¬é‡)
# ==========================================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ æ­£åœ¨ä½¿ç”¨è®¾å¤‡: {device} (4090 å…¨åŠ›è¾“å‡º)")

# STL-10 é¢„å¤„ç†ï¼ˆ96x96åŸå§‹å°ºå¯¸ï¼Œæ— éœ€Resizeï¼‰
transform_train = transforms.Compose([
    transforms.RandomCrop(96, padding=8),
    transforms.RandomHorizontalFlip(),
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
])

transform_test = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),
])

print("â¬‡ï¸ åŠ è½½ STL-10 æ•°æ®...")
train_full = datasets.STL10(root='./data', split='train', download=True, transform=transform_train)
test_full = datasets.STL10(root='./data', split='test', download=True, transform=transform_test)

# STL-10 ç±»åˆ«æ˜ å°„ï¼š0=é£æœº, 2=æ±½è½¦, 8=èˆ¹
target_classes = [0, 2, 8]
class_names = ["Airplane", "Automobile", "Ship"]
label_map = {0: 0, 2: 1, 8: 2}

def get_subset(dataset, classes, limit=None):
    indices = [i for i, (_, y) in enumerate(dataset) if y in classes]
    if limit:
        indices = indices[:limit]
    return Subset(dataset, indices)

# è®­ç»ƒé›†å…¨é‡ï¼Œæµ‹è¯•é›†å–1000ä¸ªæ ·æœ¬ï¼ˆå¯†é›†ä½†ä¸å †ç§¯ï¼‰
train_dataset = get_subset(train_full, target_classes)
test_dataset = get_subset(test_full, target_classes, limit=1000)

train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)
test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)

# ==========================================
# 2. è®­ç»ƒæ¨¡å‹ (20è½®è®­ç»ƒï¼Œç¡®ä¿æé«˜åˆ†ç¦»åº¦)
# ==========================================
print("ğŸ§  å®šä¹‰ ResNet18 æ¨¡å‹...")
model = resnet18(pretrained=True)
# STL-10æ˜¯96x96ï¼Œè°ƒæ•´ResNeté€‚é…å°å°ºå¯¸
model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)
model.maxpool = nn.Identity()
model.fc = nn.Linear(512, 3)  # 3åˆ†ç±»
model = model.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)

print("ğŸ”¥ å¼€å§‹ 20 è½®æé€Ÿè®­ç»ƒ (ç›®æ ‡: æé«˜åˆ†ç¦»åº¦)...")
epochs = 30
model.train()

for epoch in range(epochs):
    running_loss = 0.0
    correct = 0
    total = 0
    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)
        targets = torch.tensor([label_map[y.item()] for y in labels], device=device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        
        running_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
    
    scheduler.step()
    if (epoch+1) % 5 == 0:
        print(f"Epoch {epoch+1}/{epochs} | Acc: {100.*correct/total:.2f}% (Loss: {running_loss/len(train_loader):.4f})")

# ä¿å­˜æ¨¡å‹
save_path = 'resnet18_stl10_lda.pth'
torch.save(model.state_dict(), save_path)
print(f"âœ… è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ° {save_path}")

# ==========================================
# 3. æ ¸å¿ƒï¼šLDAé™ç»´ (æœ‰ç›‘ç£ï¼Œå¼ºåˆ¶ç±»åˆ«åˆ†ç¦»)
# ==========================================
print("ğŸ“‰ æå–ç‰¹å¾å¹¶ä½¿ç”¨ LDA è¿›è¡Œå®Œç¾é™ç»´...")
feature_extractor = nn.Sequential(*list(model.children())[:-1])
feature_extractor.eval()

features_list = []
labels_list = []

with torch.no_grad():
    for inputs, labels in test_loader:
        inputs = inputs.to(device)
        feats = feature_extractor(inputs).squeeze().cpu().numpy()
        # å¤„ç†æ‰¹é‡ä¸º1çš„æƒ…å†µ
        if len(feats.shape) == 1:
            feats = feats[np.newaxis, :]
        features_list.append(feats)
        labels_list.append(labels.numpy())

X = np.concatenate(features_list)
y = np.concatenate(labels_list)
y_mapped = np.array([label_map[l] for l in y])

# LDAé™ç»´åˆ°2Dï¼ˆæœ‰ç›‘ç£ï¼Œä¸»åŠ¨æœ€å¤§åŒ–ç±»åˆ«é—´è·ç¦»ï¼‰
lda = LDA(n_components=2)
X_2d = lda.fit_transform(X, y_mapped)

# SVMæ‹ŸåˆLDAç»“æœï¼Œç»˜åˆ¶ä¸æ»‘è¾¹ç•Œ
clf = SVC(kernel="rbf", C=10, gamma='scale')
clf.fit(X_2d, y_mapped)

# ==========================================
# 4. é«˜å¯¹æ¯”åº¦å¯è§†åŒ– (å‚è€ƒCIFAR-10é€»è¾‘)
# ==========================================
plt.figure(figsize=(11, 9), dpi=200)

# è¶…ç»†å¯†ç½‘æ ¼ï¼Œè¾¹ç•Œæ›´ä¸æ»‘
x_min, x_max = X_2d[:, 0].min() - 2, X_2d[:, 0].max() + 2
y_min, y_max = X_2d[:, 1].min() - 2, X_2d[:, 1].max() + 2
xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),
                     np.arange(y_min, y_max, 0.02))

Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)

# é«˜é¥±å’Œåº¦å¯¹æ¯”è‰²ï¼ˆå‚è€ƒCIFAR-10ï¼Œé€‚é…STL-10ï¼‰
cmap_light = ListedColormap(['#FFDDDD', '#DDDDFF', '#DDFFDD'])  # æµ…çº¢/æµ…è“/æµ…ç»¿
cmap_bold = ListedColormap(['#CC0000', '#0000CC', '#008800'])   # æ·±çº¢/æ·±è“/æ·±ç»¿

# ç»˜åˆ¶èƒŒæ™¯ï¼ˆè¾¹ç•Œå¹³æ»‘ï¼‰
plt.contourf(xx, yy, Z, cmap=cmap_light, alpha=0.8)

# ç»˜åˆ¶æ•£ç‚¹ï¼ˆç™½è¾¹+é€‚ä¸­å°ºå¯¸ï¼Œä¸å †ç§¯ï¼‰
plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y_mapped, cmap=cmap_bold,
            edgecolor='white', linewidth=0.8, s=60, alpha=0.9)

# æ ‡é¢˜å’Œæ ‡ç­¾ï¼ˆå‚è€ƒåŸæ ·å¼ï¼‰
plt.title("Perfect Classification Boundaries via ResNet18 + LDA\n(STL-10, Maximizing Class Separation)", 
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel("LDA Component 1 (Most Discriminative Axis)", fontsize=12, labelpad=10)
plt.ylabel("LDA Component 2 (Second Discriminative Axis)", fontsize=12, labelpad=10)

# è‡ªå®šä¹‰å›¾ä¾‹ï¼ˆæ›´é†’ç›®ï¼‰
patches = [
    mpatches.Patch(color='#CC0000', label='Airplane'),
    mpatches.Patch(color='#0000CC', label='Automobile'),
    mpatches.Patch(color='#008800', label='Ship')
]
plt.legend(handles=patches, loc="upper right", title="Classes", 
           fontsize=12, framealpha=0.9, shadow=True)

# ç¾åŒ–ç½‘æ ¼
plt.grid(True, linestyle='--', alpha=0.3, linewidth=0.5)
plt.tight_layout()

# ä¿å­˜é«˜åˆ†è¾¨ç‡å›¾
save_path = 'stl10_perfect_boundary.png'
plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white')
print(f"âœ… å®Œç¾åˆ†ç±»å›¾å·²ä¿å­˜: {save_path}")